{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "emission_rate = 485 #gCO2/kWh Icha, P., Lauf, T., & Kuhs, G. (2022). Entwicklung der spezifischen Treibhausgas-Emissionen des deutschen Strommix in den Jahren 1990â€”2021. Umweltbundesamt. https://www.umweltbundesamt.de/publikationen/entwicklung-der-spezifischen-kohlendioxid-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'PATH/Results*.csv'\n",
    "df_list = list()\n",
    "for f in glob(path):\n",
    "    df_list.append(pd.read_csv(f))\n",
    "df = pd.concat(df_list)\n",
    "df.Query = df.Query.apply(lambda x: x.replace('_',' '))\n",
    "df['Train_emissions'] = df.Train_energy * emission_rate\n",
    "df['Query_emissions'] = df.Query_energy * emission_rate\n",
    "df['Emissions (gr)'] = (df.Train_emissions + df.Query_emissions)\n",
    "df = df[df.Percent <= 10.5]\n",
    "df.to_csv('PATH/ActiveVisuals.csv', index = False)\n",
    "path = 'PATH/Baseline*.csv'\n",
    "df_list = list()\n",
    "for f in glob(path):\n",
    "    df_list.append(pd.read_csv(f))\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv('PATH/ActiveVisualsBaseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>F1</th>\n",
       "      <th>Query</th>\n",
       "      <th>Round</th>\n",
       "      <th>Trainset_absolute</th>\n",
       "      <th>Query_absolute</th>\n",
       "      <th>Test_absolute</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Train_duration</th>\n",
       "      <th>Query_duration</th>\n",
       "      <th>Train_emissions</th>\n",
       "      <th>Query_emissions</th>\n",
       "      <th>Emissions (gr)</th>\n",
       "      <th>Baseline_Emissions</th>\n",
       "      <th>Baseline_F1</th>\n",
       "      <th>Random_F1</th>\n",
       "      <th>Random_Percent</th>\n",
       "      <th>Random_Train_emissions</th>\n",
       "      <th>Random_Query_emissions</th>\n",
       "      <th>Random_Emissions (gr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claimbuster</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Breaking Ties</td>\n",
       "      <td>16</td>\n",
       "      <td>915</td>\n",
       "      <td>10616</td>\n",
       "      <td>7060</td>\n",
       "      <td>7.94</td>\n",
       "      <td>78.382991</td>\n",
       "      <td>97.877057</td>\n",
       "      <td>15.091857</td>\n",
       "      <td>34.672649</td>\n",
       "      <td>49.764506</td>\n",
       "      <td>72.915807</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.77</td>\n",
       "      <td>9.24</td>\n",
       "      <td>20.310407</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>20.310580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NewsTopic</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Breaking Ties</td>\n",
       "      <td>9</td>\n",
       "      <td>500</td>\n",
       "      <td>4534</td>\n",
       "      <td>3081</td>\n",
       "      <td>9.93</td>\n",
       "      <td>43.881368</td>\n",
       "      <td>43.579526</td>\n",
       "      <td>4.859323</td>\n",
       "      <td>9.218203</td>\n",
       "      <td>14.077525</td>\n",
       "      <td>32.710314</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>9.93</td>\n",
       "      <td>4.863947</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>4.864024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data    F1          Query  Round  Trainset_absolute  Query_absolute  \\\n",
       "0  Claimbuster  0.80  Breaking Ties     16                915           10616   \n",
       "1    NewsTopic  0.63  Breaking Ties      9                500            4534   \n",
       "\n",
       "   Test_absolute  Percent  Train_duration  Query_duration  Train_emissions  \\\n",
       "0           7060     7.94       78.382991       97.877057        15.091857   \n",
       "1           3081     9.93       43.881368       43.579526         4.859323   \n",
       "\n",
       "   Query_emissions  Emissions (gr)  Baseline_Emissions  Baseline_F1  \\\n",
       "0        34.672649       49.764506           72.915807         0.84   \n",
       "1         9.218203       14.077525           32.710314         0.89   \n",
       "\n",
       "   Random_F1  Random_Percent  Random_Train_emissions  Random_Query_emissions  \\\n",
       "0       0.77            9.24               20.310407                0.000173   \n",
       "1       0.70            9.93                4.863947                0.000078   \n",
       "\n",
       "   Random_Emissions (gr)  \n",
       "0              20.310580  \n",
       "1               4.864024  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data_size(path:str = 'PATH/data/'):\n",
    "    path += '*.csv'\n",
    "    dict_list = list()\n",
    "    for file in glob(path):\n",
    "        name = file.split('/')[-1].split('.')[0]\n",
    "        df = pd.read_csv(file)\n",
    "        size = len(df)\n",
    "        dict_list.append(dict(\n",
    "            Data = name,\n",
    "            Size = size,  \n",
    "        ))\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    return df\n",
    "\n",
    "def add_baseline(dataset, metric, path = 'PATH/ActiveLearner/'):\n",
    "    emission_rate = 485\n",
    "    path += 'Baseline*.csv'\n",
    "    df_list = list()\n",
    "    for f in glob(path):\n",
    "        df_list.append(pd.read_csv(f))\n",
    "    df = pd.concat(df_list)\n",
    "    df['Baseline_Emissions'] = df['Train_energy'] * emission_rate\n",
    "    try:\n",
    "        return df.loc[df.Data == dataset, metric][0]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "def get_stats(path = 'PATH/'):\n",
    "    path += 'Results*.csv'\n",
    "    df_list = list()\n",
    "    for f in glob(path):\n",
    "        df_list.append(pd.read_csv(f))\n",
    "    df = pd.concat(df_list)\n",
    "    df.Query = df.Query.apply(lambda x: x.replace('_',' '))\n",
    "    df['Train_emissions'] = df.Train_energy * emission_rate\n",
    "    df['Query_emissions'] = df.Query_energy * emission_rate\n",
    "    df['Emissions (gr)'] = (df.Train_emissions + df.Query_emissions)\n",
    "    df = df[df.Percent <= 10]\n",
    "    row_list = list()\n",
    "    for name, group in df.groupby(['Data', 'Query']):\n",
    "        group.loc[:,'Train_emissions'] = group['Train_emissions'].cumsum()\n",
    "        group.loc[:,'Query_emissions'] = group['Query_emissions'].cumsum()\n",
    "        group.loc[:,'Emissions (gr)'] = group['Emissions (gr)'].cumsum()\n",
    "        row_list.append(group.iloc[group.F1.idxmax(),:])\n",
    "    stats = pd.DataFrame(row_list)[['F1', 'Query', 'Data','Round',\n",
    "        'Trainset_absolute', 'Query_absolute', 'Test_absolute', 'Percent',\n",
    "        'Train_duration',\n",
    "        'Query_duration',  'Train_emissions', 'Query_emissions',\n",
    "        'Emissions (gr)']]\n",
    "    return stats\n",
    "\n",
    "def get_complete_stats(path = 'PATH/'):\n",
    "    stats = get_stats(path = path)\n",
    "    stats.Data = stats.Data.apply(lambda x : helper(x))\n",
    "    metric = 'Baseline_Emissions'\n",
    "    stats[metric] = stats.Data.apply(lambda dataset: add_baseline(dataset, metric))\n",
    "    stats['Baseline_F1'] = stats.Data.apply(lambda dataset: add_baseline(dataset, 'F1'))\n",
    "    return stats\n",
    "\n",
    "def join_random(stats):\n",
    "    rand = stats[stats.Query=='Random Sampling']\n",
    "    cols = {orig:f\"Random_{orig}\" for orig in ['F1', 'Percent','Train_emissions', 'Query_emissions', 'Emissions (gr)']}\n",
    "    rand = rand.rename(columns=cols)\n",
    "    rand = rand[['Data']+list(cols.values())]\n",
    "    active = stats[stats.Query!='Random Sampling']\n",
    "    row_list = list()\n",
    "    for name, group in active.groupby('Data'):    \n",
    "        row_list.append(group.iloc[group.reset_index(drop=True).F1.idxmax(),:])\n",
    "    active = pd.DataFrame(row_list)\n",
    "    return active.set_index('Data').join(rand.set_index('Data')).reset_index()\n",
    "\n",
    "def helper(x):\n",
    "    if x == '10k_newsarticles' or x == '10k_Newsarticles':\n",
    "        return 'NewsTopic'\n",
    "    elif x == 'GermevalFactClaiming':\n",
    "        return 'ClaimDetection'\n",
    "    elif x == 'COLA':\n",
    "        return 'Cola'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def reformat(stats):    \n",
    "    stats['Max Difference'] = (stats['F1'] - stats['Baseline_F1'])*100\n",
    "    stats['Random Difference'] = (stats['F1'] - stats['Random_F1'])*100\n",
    "    stats['Percent Difference'] = (stats['Percent'] - stats['Random_Percent'])\n",
    "    stats['Max Training Factor'] = stats['Train_emissions']/stats['Baseline_Emissions']\n",
    "    stats['Max Query Factor'] = stats['Query_emissions']/stats['Baseline_Emissions']\n",
    "    size_df = get_data_size()\n",
    "    size_df.Data = size_df.Data.apply(lambda x : helper(x))\n",
    "    stats = stats.set_index('Data').join(size_df.set_index('Data')).reset_index()\n",
    "    return stats[['Data','Query','Percent','Percent Difference','Max Difference', 'Random Difference', 'Max Training Factor', 'Max Query Factor', 'Size']].round(2)\n",
    "\n",
    "path = '/home/sami/READER_REPO/Stats/Data/ActiveLearner/Paper/'\n",
    "stats = get_complete_stats()\n",
    "stats = join_random(stats)\n",
    "stats.to_csv(path + 'full_stats.csv', index=False)\n",
    "stats = reformat(stats)\n",
    "stats.to_csv(path + 'for_plotting.csv', index=False)\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tweaking(params:list):\n",
    "    df_list = list()\n",
    "    for param in params:\n",
    "        stats = get_complete_stats(f\"PATH/{param}/\")\n",
    "        stats = join_random(stats)\n",
    "        stats['Parameter'] = param\n",
    "        df_list.append(stats)\n",
    "    df = pd.concat(df_list)\n",
    "    return df\n",
    "params = [\n",
    "    'Step50',\n",
    "    'Step100',\n",
    "    'Step250',\n",
    "    'Pool50',\n",
    "    'Pool70'\n",
    "]\n",
    "df = parameter_tweaking(params)\n",
    "df = df[df.Data.isin(['AG_News', 'Claimbuster', 'NewsTopic'])]\n",
    "df.to_csv('PATH/ParamTweaking.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'PATH/*.csv'\n",
    "dict_list = list()\n",
    "for file in glob(path):\n",
    "    name = file.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_csv(file)\n",
    "    size = len(df)\n",
    "    labels = df.label.unique().shape[0]\n",
    "    balance = list(df.label.value_counts()/len(df))\n",
    "    dict_list.append(dict(\n",
    "        name = name,\n",
    "        size = size,\n",
    "        label = labels,\n",
    "        balance = balance\n",
    "    ))\n",
    "df = pd.DataFrame(dict_list)\n",
    "df.sort_values(['size', 'label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "270c9eefaae96c25ab95f8d121212a616801941e8c06ac4b1278c74bddb4b94c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
